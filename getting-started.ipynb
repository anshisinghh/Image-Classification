{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c58e1257-7925-4cef-9209-1381e2f5e5f1",
   "metadata": {},
   "source": [
    "1. Install Dependencies and Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa913ab-2472-42d6-8d5d-09cb6969f7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad48f08-2fef-4a3b-b2db-d53ca00db25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00dca0b-ca08-4507-b8b3-4c7e00a6996b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af83462-7e5c-486f-a3cd-8b92f012bc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a0bcc3-7739-493f-8215-388e9ebcf7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3bc400-1654-4a3f-b8c3-980f82fd5395",
   "metadata": {},
   "source": [
    "2. Remove Dodgy Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71f7191-84cc-4ff3-b723-d6ae87eb19c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imghdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eded358b-61ce-4abf-9a1f-44a13a503dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f165cf1-94ae-456b-9c52-f730deef63de",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_exts = ['jpeg','jpg', 'bmp', 'png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3a2fd5-6536-453b-83ed-a6ec9dba1fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_class in os.listdir(data_dir):   \n",
    "    image_class_path = os.path.join(data_dir, image_class)\n",
    "    \n",
    "    if not os.path.isdir(image_class_path):\n",
    "        continue\n",
    "        \n",
    "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
    "        image_path = os.path.join(data_dir, image_class, image)\n",
    "        try: \n",
    "            img = cv2.imread(image_path)\n",
    "            tip = imghdr.what(image_path)\n",
    "            if tip not in image_exts: \n",
    "                print('Image not in ext list {}'.format(image_path))\n",
    "                os.remove(image_path)\n",
    "        except Exception as e: \n",
    "            print('Issue with image {}'.format(image_path))\n",
    "            os.remove(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16b698b-3ec1-4316-8495-18f1318dd15f",
   "metadata": {},
   "source": [
    "3. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbfe2da-3779-4f96-984d-0e43a759667a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdc8d5e-425b-4855-a4bc-929318a4c9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.keras.utils.image_dataset_from_directory('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8180a77-d68c-4167-b10d-aa5d77aed695",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iterator = data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d432e16-67a2-4f8c-a064-94fdd6715ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class 0 - Happy People\n",
    "# Class 1 - Sad People \n",
    "batch = data_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7c9f23-3018-4cfa-a7db-83505e699b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx, img in enumerate(batch[0][:4]):\n",
    "    ax[idx].imshow(img.astype(int))\n",
    "    ax[idx].title.set_text(batch[1][idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c59622-a775-4c49-b92b-3dd4dcae8eb4",
   "metadata": {},
   "source": [
    "4. Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220f1ddc-04a2-494e-8b99-5777adf42f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(lambda x,y: (x/255, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dde1519-e50a-4f4e-851a-645e0a15fbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce10d4c-ecc9-4cbe-8038-cdff05842f6f",
   "metadata": {},
   "source": [
    "5. Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4659ec6-b464-4700-aec3-6c0b76da42b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data)*.7)\n",
    "val_size = int(len(data)*.2)\n",
    "test_size = int(len(data)*.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752665d8-bfaf-4761-aff6-a380cc30dad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6180465e-7faf-4c1e-a068-0f3ad22b8582",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.take(train_size)\n",
    "val = data.skip(train_size).take(val_size)\n",
    "test = data.skip(train_size+val_size).take(test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79afed2e-dc44-4019-8401-96b31fe19782",
   "metadata": {},
   "source": [
    "6. Build Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae44e1a-dac3-474a-b915-c28588a6357b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece87f77-21cd-42b4-a69c-817bd588f1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd89c06-73b2-4777-b5bd-d97137129866",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693ad43e-5c5e-454f-a17d-36dfdd96664d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(256,256,3)))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(32, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(16, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f399ce-f951-4f43-940c-83ab0ba5c86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam', loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3806dfe-8605-411c-b2c9-ae1e9ab15a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893f3e24-1ab5-4394-98a9-c7eeefb5ab50",
   "metadata": {},
   "source": [
    "7. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bd5381-82df-4e15-b712-c7b3600b3440",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir='logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60df71e5-d019-445f-9627-b31f988081c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80766f3a-0341-4455-bac7-84acaffd3095",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(train, epochs=20, validation_data=val, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09125f2c-4936-4289-a301-aa6371fb0ee7",
   "metadata": {},
   "source": [
    "8. Plot Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35066cc6-45ee-4c79-8a7d-30227d82428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
    "plt.plot(hist.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4b9b53-68b6-4fa2-b756-3f59224fdb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['accuracy'], color='teal', label='accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48a39bc-823f-45e8-8837-ce27dbabd762",
   "metadata": {},
   "source": [
    "9. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4eb173-c03f-4eea-ad83-333e0866e295",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e7477f-4855-4967-b2d9-956bb1d845b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5640a524-3852-42fe-8e9e-10694d9e536b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test.as_numpy_iterator():\n",
    "    X, y = batch\n",
    "    yhat = model.predict(X)\n",
    "    pre.update_state(y, yhat)\n",
    "    re.update_state(y, yhat)\n",
    "    acc.update_state(y, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55764879-6c58-4cbe-8507-7ca0070a8bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Precision: {pre.result().numpy()}')\n",
    "print(f'Recall: {re.result().numpy()}')\n",
    "print(f'Accuracy: {acc.result().numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a758ab-5bee-4b34-969a-cfaa74b6e4ad",
   "metadata": {},
   "source": [
    "10. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6ef215-7184-466e-a1de-dbafca901d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd36937f-dcf4-4a4a-b01a-61e719d09580",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('happytest.jpg')\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112be30d-c337-4f25-94ea-5a3dc6f86383",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = tf.image.resize(img, (256,256))\n",
    "plt.imshow(resize.numpy().astype(int))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2f683d-1cf2-41cf-9e4e-b923bc1d679d",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(np.expand_dims(resize/255, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08fc1ca-bcd5-44d4-925f-d424e2269115",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d366b11-40a0-4f08-8890-839a73e24d27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if yhat > 0.5: \n",
    "    print(f'Predicted class is Sad')\n",
    "else:\n",
    "    print(f'Predicted class is Happy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccda49c9-2d97-4155-8942-870913d7ab5d",
   "metadata": {},
   "source": [
    "11. Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05338de-ea7d-459f-ba5b-46055243f5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136c42cc-19fd-4c1a-96c1-5dd85ff62e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join('models', 'imageclassifier.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1861012-bfe8-41b3-833f-fd39d586061c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ba8064-2848-4fc2-a72d-f1565129e782",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.predict(np.expand_dims(resize/255, 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imageclassification",
   "language": "python",
   "name": "imageclassification"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
